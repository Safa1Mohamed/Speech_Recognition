{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "SR_Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "izoulkRJFcup",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "99e1b329-0460-4964-d77d-a007ee32351a"
      },
      "source": [
        "# Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnvKA91fFgyK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "8f445a39-a669-48ae-ff52-1d42c8e7fe74"
      },
      "source": [
        "!pip install torchaudio\n",
        "!pip install PyDrive\n",
        "!pip install soundfile"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchaudio\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/0a/40e53c686c2af65b2a4e818d11d9b76fa79178440caf99f3ceb2a32c3b04/torchaudio-0.5.1-cp36-cp36m-manylinux1_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch==1.5.1 in /usr/local/lib/python3.6/dist-packages (from torchaudio) (1.5.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1->torchaudio) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1->torchaudio) (0.16.0)\n",
            "Installing collected packages: torchaudio\n",
            "Successfully installed torchaudio-0.5.1\n",
            "Requirement already satisfied: PyDrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (4.1.3)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (3.13)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (1.7.12)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (1.12.0)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.17.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.2.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (4.6)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.8)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.17.2)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.0.3)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.1)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (47.3.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (4.1.0)\n",
            "Collecting soundfile\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/f2/3cbbbf3b96fb9fa91582c438b574cff3f45b29c772f94c400e2c99ef5db9/SoundFile-0.10.3.post1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile) (1.14.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile) (2.20)\n",
            "Installing collected packages: soundfile\n",
            "Successfully installed soundfile-0.10.3.post1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jzzuGAMna4NG",
        "colab": {}
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-hQWM54HG0R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "a8a1bc8d-b954-4d78-de13-15d01372b170"
      },
      "source": [
        "! git clone https://github.com/facebookresearch/CPC_audio.git"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'CPC_audio'...\n",
            "remote: Enumerating objects: 84, done.\u001b[K\n",
            "remote: Counting objects: 100% (84/84), done.\u001b[K\n",
            "remote: Compressing objects: 100% (65/65), done.\u001b[K\n",
            "remote: Total 84 (delta 13), reused 75 (delta 6), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (84/84), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gWFtgshDVYS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "outputId": "c4a02b42-bbbe-448b-ab54-7e5291cf582c"
      },
      "source": [
        "%cd /content/CPC_audio\n",
        "!python setup.py develop"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/CPC_audio\n",
            "Compiling cpc/eval/ABX/dtw.pyx because it changed.\n",
            "[1/1] Cythonizing cpc/eval/ABX/dtw.pyx\n",
            "running develop\n",
            "running egg_info\n",
            "creating CPC_audio.egg-info\n",
            "writing CPC_audio.egg-info/PKG-INFO\n",
            "writing dependency_links to CPC_audio.egg-info/dependency_links.txt\n",
            "writing top-level names to CPC_audio.egg-info/top_level.txt\n",
            "writing manifest file 'CPC_audio.egg-info/SOURCES.txt'\n",
            "writing manifest file 'CPC_audio.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "building 'cpc.eval.ABX.dtw' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-3.6\n",
            "creating build/temp.linux-x86_64-3.6/cpc\n",
            "creating build/temp.linux-x86_64-3.6/cpc/eval\n",
            "creating build/temp.linux-x86_64-3.6/cpc/eval/ABX\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/numpy/core/include -I/usr/include/python3.6m -c cpc/eval/ABX/dtw.c -o build/temp.linux-x86_64-3.6/cpc/eval/ABX/dtw.o\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1832:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kcpc/eval/ABX/dtw.c:625\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
            " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
            "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "creating build/lib.linux-x86_64-3.6\n",
            "creating build/lib.linux-x86_64-3.6/cpc\n",
            "creating build/lib.linux-x86_64-3.6/cpc/eval\n",
            "creating build/lib.linux-x86_64-3.6/cpc/eval/ABX\n",
            "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cpc/eval/ABX/dtw.o -o build/lib.linux-x86_64-3.6/cpc/eval/ABX/dtw.cpython-36m-x86_64-linux-gnu.so\n",
            "copying build/lib.linux-x86_64-3.6/cpc/eval/ABX/dtw.cpython-36m-x86_64-linux-gnu.so -> cpc/eval/ABX\n",
            "Creating /usr/local/lib/python3.6/dist-packages/CPC-audio.egg-link (link to .)\n",
            "Adding CPC-audio 1.0 to easy-install.pth file\n",
            "\n",
            "Installed /content/CPC_audio\n",
            "Processing dependencies for CPC-audio==1.0\n",
            "Finished processing dependencies for CPC-audio==1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lImFBRyHIMX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchaudio"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f9BrweAIla4J",
        "colab": {}
      },
      "source": [
        "# Several functions that will be necessary to load the data later\n",
        "from cpc.dataset import findAllSeqs, AudioBatchData, parseSeqLabels\n",
        "SIZE_WINDOW = 20480\n",
        "BATCH_SIZE=8\n",
        "def load_dataset(path_dataset, file_extension='.wav', phone_label_dict=None):\n",
        "  data_list, speakers = findAllSeqs(path_dataset, extension=file_extension)\n",
        "  dataset = AudioBatchData(path_dataset, SIZE_WINDOW, data_list, phone_label_dict, len(speakers))\n",
        "  return dataset"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "srPM5r_LB9v-"
      },
      "source": [
        "# Fine tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0Nb_-0IQiJk9"
      },
      "source": [
        "## Phone separability with aligned phonemes.\n",
        "\n",
        "One option to evaluate the quality of the features trained with CPC can be to check if they can be used to recognize phonemes. \n",
        "To do so, we can fine-tune a pre-trained model using a limited amount of labelled speech data.\n",
        "We are going to start with a simple evaluation setting where we have the phone labels for each timestep corresponding to a CPC feature.\n",
        "\n",
        "We will work with a model already pre-trained on English data. As far as the fine-tuning dataset is concerned, we will use a 1h subset of [librispeech-100](http://www.openslr.org/12/). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N-scDMAasXxc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "1cea5f13-4136-4902-9248-1ca66339cd27"
      },
      "source": [
        "!mkdir checkpoint_data\n",
        "!wget https://dl.fbaipublicfiles.com/librilight/CPC_checkpoints/not_hub/2levels_6k_top_ctc/checkpoint_30.pt -P checkpoint_data\n",
        "!wget https://dl.fbaipublicfiles.com/librilight/CPC_checkpoints/not_hub/2levels_6k_top_ctc/checkpoint_logs.json -P checkpoint_data\n",
        "!wget https://dl.fbaipublicfiles.com/librilight/CPC_checkpoints/not_hub/2levels_6k_top_ctc/checkpoint_args.json -P checkpoint_data\n",
        "!ls checkpoint_data"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-07 01:13:40--  https://dl.fbaipublicfiles.com/librilight/CPC_checkpoints/not_hub/2levels_6k_top_ctc/checkpoint_30.pt\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.74.142, 104.22.75.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 113599715 (108M) [application/octet-stream]\n",
            "Saving to: ‘checkpoint_data/checkpoint_30.pt’\n",
            "\n",
            "checkpoint_30.pt    100%[===================>] 108.34M  22.0MB/s    in 5.5s    \n",
            "\n",
            "2020-07-07 01:13:46 (19.6 MB/s) - ‘checkpoint_data/checkpoint_30.pt’ saved [113599715/113599715]\n",
            "\n",
            "--2020-07-07 01:13:48--  https://dl.fbaipublicfiles.com/librilight/CPC_checkpoints/not_hub/2levels_6k_top_ctc/checkpoint_logs.json\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.74.142, 104.22.75.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20786 (20K) [text/plain]\n",
            "Saving to: ‘checkpoint_data/checkpoint_logs.json’\n",
            "\n",
            "checkpoint_logs.jso 100%[===================>]  20.30K  --.-KB/s    in 0.09s   \n",
            "\n",
            "2020-07-07 01:13:49 (221 KB/s) - ‘checkpoint_data/checkpoint_logs.json’ saved [20786/20786]\n",
            "\n",
            "--2020-07-07 01:13:50--  https://dl.fbaipublicfiles.com/librilight/CPC_checkpoints/not_hub/2levels_6k_top_ctc/checkpoint_args.json\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.74.142, 104.22.75.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2063 (2.0K) [text/plain]\n",
            "Saving to: ‘checkpoint_data/checkpoint_args.json’\n",
            "\n",
            "checkpoint_args.jso 100%[===================>]   2.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-07-07 01:13:51 (19.8 MB/s) - ‘checkpoint_data/checkpoint_args.json’ saved [2063/2063]\n",
            "\n",
            "checkpoint_30.pt  checkpoint_args.json\tcheckpoint_logs.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xkKi-qfosng2"
      },
      "source": [
        "Then we will use a simple linear classifier to recognize the phonemes from the features produced by ```cpc_model```. \n",
        "\n",
        "### a) Build the phone classifier \n",
        "\n",
        "Design a class of linear classifiers, ```PhoneClassifier``` that will take as input a batch of sequences of CPC features and output a score vector for each phoneme"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4RpAbz-0CXJJ",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "class PhoneClassifier(torch.nn.Module):\n",
        "\n",
        "  def __init__(self,input_dim : int,n_phones : int):\n",
        "    super(PhoneClassifier, self).__init__()\n",
        "    self.linear = torch.nn.Linear(input_dim, n_phones)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    return self.linear(x)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Zt5oa_nqtH-d"
      },
      "source": [
        "Our phone classifier will then be:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TdfWDiFnylMT"
      },
      "source": [
        "## Phone separability without alignment (PER)\n",
        "\n",
        "Aligned data are very practical, but un real life they are rarely available. That's why in this excercise we will consider a fine-tuning with non-aligned phonemes.\n",
        "\n",
        "The model, the optimizer and the phone classifier will stay the same. However, we will replace our phone criterion with a [CTC loss](https://pytorch.org/docs/master/generated/torch.nn.CTCLoss.html). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Zsgjv3cD0oqD",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def train_one_epoch_ctc(cpc_model,phone_classifier,loss_criterion,data_loader,optimizer):\n",
        "  \n",
        "  cpc_model.train()\n",
        "  loss_criterion.train()\n",
        "\n",
        "  avg_loss = 0\n",
        "  avg_accuracy = 0\n",
        "  n_items = 0\n",
        "  for step, full_data in enumerate(data_loader):\n",
        "\n",
        "    x, x_len, y, y_len = full_data\n",
        "\n",
        "    x_batch_len = x.shape[-1]\n",
        "    x, y = x.to(device), y.to(device)\n",
        "\n",
        "    bs=x.size(0)\n",
        "    optimizer.zero_grad()\n",
        "    context_out, enc_out, _ = cpc_model(x.to(device),y.to(device))\n",
        "  \n",
        "    scores = phone_classifier(context_out)\n",
        "    scores = scores.permute(1,0,2)\n",
        "    scores = F.log_softmax(scores,2)\n",
        "    yhat_len = torch.tensor([int(scores.shape[0]*x_len[i]/x_batch_len) for i in range(scores.shape[1])]) # this is an approximation, should be good enough\n",
        "\n",
        "    loss = loss_criterion(scores,y.to(device),yhat_len,y_len)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    avg_loss+=loss.item()*bs\n",
        "    n_items+=bs\n",
        "  avg_loss/=n_items\n",
        "  return avg_loss\n",
        "\n",
        "def validation_step(cpc_model,phone_classifier,loss_criterion,data_loader):\n",
        "\n",
        "  cpc_model.eval()\n",
        "  phone_classifier.eval()\n",
        "  avg_loss = 0\n",
        "  avg_accuracy = 0\n",
        "  n_items = 0\n",
        "  with torch.no_grad():\n",
        "    for step, full_data in enumerate(data_loader):\n",
        "\n",
        "      x, x_len, y, y_len = full_data\n",
        "\n",
        "      x_batch_len = x.shape[-1]\n",
        "      x, y = x.to(device), y.to(device)\n",
        "\n",
        "      bs=x.size(0)\n",
        "      context_out, enc_out, _ = cpc_model(x.to(device),y.to(device))\n",
        "    \n",
        "      scores = phone_classifier(context_out)\n",
        "      scores = scores.permute(1,0,2)\n",
        "      scores = F.log_softmax(scores,2)\n",
        "      yhat_len = torch.tensor([int(scores.shape[0]*x_len[i]/x_batch_len) for i in range(scores.shape[1])]) # this is an approximation, should be good enough\n",
        "\n",
        "      loss = loss_criterion(scores,y.to(device),yhat_len,y_len)\n",
        "      avg_loss+=loss.item()*bs\n",
        "      n_items+=bs\n",
        "  avg_loss/=n_items\n",
        "\n",
        "  return avg_loss\n",
        "\n",
        "def run_ctc(cpc_model,phone_classifier,loss_criterion,data_loader_train,data_loader_val,optimizer,n_epoch):\n",
        "\n",
        "  train_loss = []\n",
        "  valid_loss = []\n",
        "  for epoch in range(n_epoch):\n",
        "\n",
        "      print(f\"Running epoch {epoch + 1} / {n_epoch}\")\n",
        "      loss_train = train_one_epoch_ctc(cpc_model, phone_classifier, loss_criterion, data_loader_train, optimizer)\n",
        "      train_loss.append(loss_train)\n",
        "      print(\"-------------------\")\n",
        "      print(f\"Training dataset :\")\n",
        "      print(f\"Average loss : {loss_train}.\")\n",
        "\n",
        "      print(\"-------------------\")\n",
        "      print(\"Validation dataset\")\n",
        "      loss_val = validation_step(cpc_model, phone_classifier, loss_criterion, data_loader_val)\n",
        "      valid_loss.append(loss_val)\n",
        "      print(f\"Average loss : {loss_val}\")\n",
        "      print(\"-------------------\")\n",
        "      print()\n",
        "  return train_loss, valid_loss"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TKrYW4gK1BBF"
      },
      "source": [
        "### b- Evaluation: the Phone Error Rate (PER)\n",
        "\n",
        "In order to compute the similarity between two sequences, we can use the [Levenshtein distance](https://en.wikipedia.org/wiki/Levenshtein_distance). This distance estimates the minimum number of insertion, deletion and addition to move from one sequence to another. If we normalize this distance by the number of characters in the reference sequence we get the Phone Error Rate (PER).\n",
        "\n",
        "This value can be interpreted as :\n",
        "\\\\[  PER = \\frac{S + D + I}{N} \\\\]\n",
        "\n",
        "Where:\n",
        "\n",
        "\n",
        "*   N is the number of characters in the reference\n",
        "*   S is the number of substitutiion\n",
        "*   I in the number of insertion\n",
        "*   D in the number of deletion\n",
        "\n",
        "For the best possible alignment of the two sequences.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RoBhsx7GNqI_",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_PER_sequence(ref_seq, target_seq):\n",
        "\n",
        "  # re = g.split()\n",
        "  # h = h.split()\n",
        "  n = len(ref_seq)\n",
        "  m = len(target_seq)\n",
        "\n",
        "  D = np.zeros((n+1,m+1))\n",
        "  for i in range(1,n+1):\n",
        "    D[i,0] = D[i-1,0]+1\n",
        "  for j in range(1,m+1):\n",
        "    D[0,j] = D[0,j-1]+1\n",
        "  \n",
        "  ### TODO compute the alignment\n",
        "\n",
        "  for i in range(1,n+1):\n",
        "    for j in range(1,m+1):\n",
        "      D[i,j] = min(\n",
        "          D[i-1,j]+1,\n",
        "          D[i-1,j-1]+1,\n",
        "          D[i,j-1]+1,\n",
        "          D[i-1,j-1]+ 0 if ref_seq[i-1]==target_seq[j-1] else float(\"inf\")\n",
        "      )\n",
        "  return D[n,m]/len(ref_seq)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "r-hr0KK0mgcR"
      },
      "source": [
        "You can test your function below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AfTb3yOQmvey",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "909e32b8-efe4-4d5a-c952-5dd9dc4efe70"
      },
      "source": [
        "ref_seq = [0, 1, 1, 2, 0, 2, 2]\n",
        "pred_seq = [1, 1, 2, 2, 0, 0]\n",
        "\n",
        "expected_PER = 4. / 7.\n",
        "print(get_PER_sequence(ref_seq, pred_seq) == expected_PER)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nHiyChl-m_k7"
      },
      "source": [
        "## c- Evaluating the PER of your model on the test dataset\n",
        "\n",
        "Evaluate the PER on the validation dataset. Please notice that you should usually use a separate dataset, called the dev dataset, to perform this operation. However for the sake of simplicity we will work with validation data in this exercise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DMkX0PoFnclg",
        "colab": {}
      },
      "source": [
        "import progressbar\n",
        "from multiprocessing import Pool\n",
        "\n",
        "def cut_data(seq, sizeSeq):\n",
        "    maxSeq = sizeSeq.max()\n",
        "    return seq[:, :maxSeq]\n",
        "\n",
        "\n",
        "def prepare_data(data):\n",
        "    seq, sizeSeq, phone, sizePhone = data\n",
        "    seq = seq.cuda()\n",
        "    phone = phone.cuda()\n",
        "    sizeSeq = sizeSeq.cuda().view(-1)\n",
        "    sizePhone = sizePhone.cuda().view(-1)\n",
        "\n",
        "    seq = cut_data(seq.permute(0, 2, 1), sizeSeq).permute(0, 2, 1)\n",
        "    return seq, sizeSeq, phone, sizePhone\n",
        "\n",
        "\n",
        "def get_per(test_dataloader,cpc_model,phone_classifier):\n",
        "\n",
        "  downsampling_factor = 160\n",
        "  cpc_model.eval()\n",
        "  phone_classifier.eval()\n",
        "\n",
        "  avgPER = 0\n",
        "  nItems = 0 \n",
        "\n",
        "  print(\"Starting the PER computation through beam search\")\n",
        "  bar = progressbar.ProgressBar(maxval=len(test_dataloader))\n",
        "  bar.start()\n",
        "\n",
        "  for index, data in enumerate(test_dataloader):\n",
        "\n",
        "    bar.update(index)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      \n",
        "        seq, sizeSeq, phone, sizePhone = prepare_data(data)\n",
        "        c_feature, _, _ = cpc_model(seq.to(device),phone.to(device))\n",
        "        sizeSeq = sizeSeq / downsampling_factor\n",
        "        predictions = torch.nn.functional.softmax(\n",
        "        phone_classifier(c_feature), dim=2).cpu()\n",
        "        phone = phone.cpu()\n",
        "        sizeSeq = sizeSeq.cpu()\n",
        "        sizePhone = sizePhone.cpu()\n",
        "\n",
        "        bs = c_feature.size(0)\n",
        "        data_per = [(predictions[b].argmax(1),  phone[b]) for b in range(bs)]\n",
        "        # data_per = [(predictions[b], sizeSeq[b], phone[b], sizePhone[b],\n",
        "        #               \"criterion.module.BLANK_LABEL\") for b in range(bs)]\n",
        "\n",
        "        with Pool(bs) as p:\n",
        "            poolData = p.starmap(get_PER_sequence, data_per)\n",
        "        avgPER += sum([x for x in poolData])\n",
        "        nItems += len(poolData)\n",
        "\n",
        "  bar.finish()\n",
        "\n",
        "  avgPER /= nItems\n",
        "\n",
        "  print(f\"Average CER {avgPER}\")\n",
        "  return avgPER"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "p8e9D7g8159k"
      },
      "source": [
        "## Character error rate (CER) \n",
        "\n",
        "The Character Error Rate (CER) is an evaluation metric similar to the PER but with characters insterad of phonemes. Using the following data, run the functions you defined previously to estimate the CER of your model after fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cXONmKQOuFSn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "41595a69-5812-4dc9-c8a5-40345e814bb1"
      },
      "source": [
        "# Load a dataset labelled with the letters of each sequence.\n",
        "%cd /content/CPC_audio\n",
        "from cpc.eval.common_voices_eval import SingleSequenceDataset, parseSeqLabels, findAllSeqs\n",
        "path_train_data_cer = '/content/gdrive/My Drive/Data/train_set'\n",
        "path_val_data_cer = '/content/gdrive/My Drive/Data/validation_set'\n",
        "path_test_data_cer = '/content/gdrive/My Drive/Data/test_set'\n",
        "path_letter_data_cer = '/content/gdrive/My Drive/Data/all_sessions.txt'\n",
        "BATCH_SIZE=8\n",
        "\n",
        "letters_labels, N_LETTERS = parseSeqLabels(path_letter_data_cer)\n",
        "data_train_cer, _ = findAllSeqs(path_train_data_cer, extension='.wav')\n",
        "dataset_train_non_aligned = SingleSequenceDataset(path_train_data_cer, data_train_cer, letters_labels)\n",
        "\n",
        "data_val_cer, _ = findAllSeqs(path_val_data_cer, extension='.wav')\n",
        "dataset_val_non_aligned = SingleSequenceDataset(path_val_data_cer, data_val_cer, letters_labels)\n",
        "\n",
        "data_test_cer, _ = findAllSeqs(path_test_data_cer, extension='.wav')\n",
        "dataset_test_non_aligned = SingleSequenceDataset(path_test_data_cer,data_test_cer,letters_labels)\n",
        "\n",
        "# The data loader will generate a tuple of tensors data, labels for each batch\n",
        "# data : size N x T1 x 1 : the audio sequence\n",
        "# label : size N x T2 the sequence of letters corresponding to the audio data\n",
        "# IMPORTANT NOTE: just like the PER the CER is computed with non-aligned phone data.\n",
        "\n",
        "data_loader_train_letters = torch.utils.data.DataLoader(dataset_train_non_aligned, batch_size=BATCH_SIZE,shuffle=True)\n",
        "data_loader_val_letters = torch.utils.data.DataLoader(dataset_val_non_aligned, batch_size=BATCH_SIZE,shuffle=True)\n",
        "data_loader_test_letters = torch.utils.data.DataLoader(dataset_test_non_aligned,batch_size=BATCH_SIZE,shuffle=True)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11it [00:00, 441.12it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/CPC_audio\n",
            "Saved cache file at /content/gdrive/My Drive/Data/train_set/_seqs_cache.txt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "4it [00:00, 242.21it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loaded 506 sequences in 3.79 seconds\n",
            "maxSizeSeq : 271161\n",
            "maxSizePhone : 66\n",
            "minSizePhone : 12\n",
            "Total size dataset 1.1242034375 hours\n",
            "Saved cache file at /content/gdrive/My Drive/Data/validation_set/_seqs_cache.txt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "10it [00:00, 470.17it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loaded 151 sequences in 2.51 seconds\n",
            "maxSizeSeq : 190938\n",
            "maxSizePhone : 66\n",
            "minSizePhone : 14\n",
            "Total size dataset 0.33736942708333334 hours\n",
            "Saved cache file at /content/gdrive/My Drive/Data/test_set/_seqs_cache.txt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loaded 449 sequences in 3.92 seconds\n",
            "maxSizeSeq : 256278\n",
            "maxSizePhone : 79\n",
            "minSizePhone : 4\n",
            "Total size dataset 1.3762615625 hours\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9h07zI2LjzAU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ee1c0700-f542-4038-d983-61b009242851"
      },
      "source": [
        "from cpc.feature_loader import loadModel\n",
        "\n",
        "checkpoint_path = 'checkpoint_data/checkpoint_30.pt'\n",
        "cpc_model, HIDDEN_CONTEXT_MODEL, HIDDEN_ENCODER_MODEL = loadModel([checkpoint_path])\n",
        "cpc_model = cpc_model.cuda()\n",
        "character_classifier = PhoneClassifier(HIDDEN_CONTEXT_MODEL, N_LETTERS).to(device)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading checkpoint checkpoint_data/checkpoint_30.pt\n",
            "Loading the state dict at checkpoint_data/checkpoint_30.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rHCNg1E7lW1L",
        "colab": {}
      },
      "source": [
        "parameters = list(character_classifier.parameters()) + list(cpc_model.parameters())\n",
        "LEARNING_RATE = 1e-3\n",
        "optimizer = torch.optim.Adam(parameters, lr=LEARNING_RATE)\n",
        "\n",
        "optimizer_frozen = torch.optim.Adam(list(character_classifier.parameters()), lr=LEARNING_RATE)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "engpkljbk9hj",
        "colab": {}
      },
      "source": [
        "loss_ctc = torch.nn.CTCLoss()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9NBHd2s2kxld",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2608cadf-31c3-44e4-9e25-3d6400064049"
      },
      "source": [
        "train_loss, valid_loss = run_ctc(cpc_model,character_classifier,loss_ctc,data_loader_train_letters,data_loader_val_letters,optimizer_frozen,n_epoch=30)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running epoch 1 / 30\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/pytorch/aten/src/ATen/native/BinaryOps.cpp:81: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------------\n",
            "Training dataset :\n",
            "Average loss : 32.89774716821047.\n",
            "-------------------\n",
            "Validation dataset\n",
            "Average loss : 16.65504684448242\n",
            "-------------------\n",
            "\n",
            "Running epoch 2 / 30\n",
            "-------------------\n",
            "Training dataset :\n",
            "Average loss : 10.652358403536352.\n",
            "-------------------\n",
            "Validation dataset\n",
            "Average loss : 7.168837642669677\n",
            "-------------------\n",
            "\n",
            "Running epoch 3 / 30\n",
            "-------------------\n",
            "Training dataset :\n",
            "Average loss : 6.604250379128032.\n",
            "-------------------\n",
            "Validation dataset\n",
            "Average loss : 5.6810811996459964\n",
            "-------------------\n",
            "\n",
            "Running epoch 4 / 30\n",
            "-------------------\n",
            "Training dataset :\n",
            "Average loss : 5.745753668794538.\n",
            "-------------------\n",
            "Validation dataset\n",
            "Average loss : 5.138261006673177\n",
            "-------------------\n",
            "\n",
            "Running epoch 5 / 30\n",
            "-------------------\n",
            "Training dataset :\n",
            "Average loss : 5.383424091339111.\n",
            "-------------------\n",
            "Validation dataset\n",
            "Average loss : 4.846726309458415\n",
            "-------------------\n",
            "\n",
            "Running epoch 6 / 30\n",
            "-------------------\n",
            "Training dataset :\n",
            "Average loss : 5.176429988370083.\n",
            "-------------------\n",
            "Validation dataset\n",
            "Average loss : 4.662105439503987\n",
            "-------------------\n",
            "\n",
            "Running epoch 7 / 30\n",
            "-------------------\n",
            "Training dataset :\n",
            "Average loss : 5.040834920713217.\n",
            "-------------------\n",
            "Validation dataset\n",
            "Average loss : 4.531768652598063\n",
            "-------------------\n",
            "\n",
            "Running epoch 8 / 30\n",
            "-------------------\n",
            "Training dataset :\n",
            "Average loss : 4.947526823648132.\n",
            "-------------------\n",
            "Validation dataset\n",
            "Average loss : 4.436032899220785\n",
            "-------------------\n",
            "\n",
            "Running epoch 9 / 30\n",
            "-------------------\n",
            "Training dataset :\n",
            "Average loss : 4.880858020027085.\n",
            "-------------------\n",
            "Validation dataset\n",
            "Average loss : 4.366380265553793\n",
            "-------------------\n",
            "\n",
            "Running epoch 10 / 30\n",
            "-------------------\n",
            "Training dataset :\n",
            "Average loss : 4.828331990289216.\n",
            "-------------------\n",
            "Validation dataset\n",
            "Average loss : 4.3084544118245445\n",
            "-------------------\n",
            "\n",
            "Running epoch 11 / 30\n",
            "-------------------\n",
            "Training dataset :\n",
            "Average loss : 4.788135642816525.\n",
            "-------------------\n",
            "Validation dataset\n",
            "Average loss : 4.261987533569336\n",
            "-------------------\n",
            "\n",
            "Running epoch 12 / 30\n",
            "-------------------\n",
            "Training dataset :\n",
            "Average loss : 4.7558359948715365.\n",
            "-------------------\n",
            "Validation dataset\n",
            "Average loss : 4.224074274698893\n",
            "-------------------\n",
            "\n",
            "Running epoch 13 / 30\n",
            "-------------------\n",
            "Training dataset :\n",
            "Average loss : 4.730128628192562.\n",
            "-------------------\n",
            "Validation dataset\n",
            "Average loss : 4.193245544433593\n",
            "-------------------\n",
            "\n",
            "Running epoch 14 / 30\n",
            "-------------------\n",
            "Training dataset :\n",
            "Average loss : 4.713026780421191.\n",
            "-------------------\n",
            "Validation dataset\n",
            "Average loss : 4.163831698099772\n",
            "-------------------\n",
            "\n",
            "Running epoch 15 / 30\n",
            "-------------------\n",
            "Training dataset :\n",
            "Average loss : 4.692591142654419.\n",
            "-------------------\n",
            "Validation dataset\n",
            "Average loss : 4.147536087036133\n",
            "-------------------\n",
            "\n",
            "Running epoch 16 / 30\n",
            "-------------------\n",
            "Training dataset :\n",
            "Average loss : 4.675780470064371.\n",
            "-------------------\n",
            "Validation dataset\n",
            "Average loss : 4.125659332275391\n",
            "-------------------\n",
            "\n",
            "Running epoch 17 / 30\n",
            "-------------------\n",
            "Training dataset :\n",
            "Average loss : 4.661308493000446.\n",
            "-------------------\n",
            "Validation dataset\n",
            "Average loss : 4.114066842397054\n",
            "-------------------\n",
            "\n",
            "Running epoch 18 / 30\n",
            "-------------------\n",
            "Training dataset :\n",
            "Average loss : 4.649187900052212.\n",
            "-------------------\n",
            "Validation dataset\n",
            "Average loss : 4.094681046803792\n",
            "-------------------\n",
            "\n",
            "Running epoch 19 / 30\n",
            "-------------------\n",
            "Training dataset :\n",
            "Average loss : 4.639925848611511.\n",
            "-------------------\n",
            "Validation dataset\n",
            "Average loss : 4.085705032348633\n",
            "-------------------\n",
            "\n",
            "Running epoch 20 / 30\n",
            "-------------------\n",
            "Training dataset :\n",
            "Average loss : 4.633964505526099.\n",
            "-------------------\n",
            "Validation dataset\n",
            "Average loss : 4.0737778790791825\n",
            "-------------------\n",
            "\n",
            "Running epoch 21 / 30\n",
            "-------------------\n",
            "Training dataset :\n",
            "Average loss : 4.621373495725122.\n",
            "-------------------\n",
            "Validation dataset\n",
            "Average loss : 4.066132624944051\n",
            "-------------------\n",
            "\n",
            "Running epoch 22 / 30\n",
            "-------------------\n",
            "Training dataset :\n",
            "Average loss : 4.612678786551598.\n",
            "-------------------\n",
            "Validation dataset\n",
            "Average loss : 4.056191883087158\n",
            "-------------------\n",
            "\n",
            "Running epoch 23 / 30\n",
            "-------------------\n",
            "Training dataset :\n",
            "Average loss : 4.605341933977486.\n",
            "-------------------\n",
            "Validation dataset\n",
            "Average loss : 4.049872589111328\n",
            "-------------------\n",
            "\n",
            "Running epoch 24 / 30\n",
            "-------------------\n",
            "Training dataset :\n",
            "Average loss : 4.599546300302638.\n",
            "-------------------\n",
            "Validation dataset\n",
            "Average loss : 4.042733090718587\n",
            "-------------------\n",
            "\n",
            "Running epoch 25 / 30\n",
            "-------------------\n",
            "Training dataset :\n",
            "Average loss : 4.590643213763095.\n",
            "-------------------\n",
            "Validation dataset\n",
            "Average loss : 4.03171571413676\n",
            "-------------------\n",
            "\n",
            "Running epoch 26 / 30\n",
            "-------------------\n",
            "Training dataset :\n",
            "Average loss : 4.587937189800905.\n",
            "-------------------\n",
            "Validation dataset\n",
            "Average loss : 4.029010581970215\n",
            "-------------------\n",
            "\n",
            "Running epoch 27 / 30\n",
            "-------------------\n",
            "Training dataset :\n",
            "Average loss : 4.581791240389984.\n",
            "-------------------\n",
            "Validation dataset\n",
            "Average loss : 4.025465447107951\n",
            "-------------------\n",
            "\n",
            "Running epoch 28 / 30\n",
            "-------------------\n",
            "Training dataset :\n",
            "Average loss : 4.575929594984149.\n",
            "-------------------\n",
            "Validation dataset\n",
            "Average loss : 4.012607669830322\n",
            "-------------------\n",
            "\n",
            "Running epoch 29 / 30\n",
            "-------------------\n",
            "Training dataset :\n",
            "Average loss : 4.571269750122977.\n",
            "-------------------\n",
            "Validation dataset\n",
            "Average loss : 4.015702133178711\n",
            "-------------------\n",
            "\n",
            "Running epoch 30 / 30\n",
            "-------------------\n",
            "Training dataset :\n",
            "Average loss : 4.567059714723341.\n",
            "-------------------\n",
            "Validation dataset\n",
            "Average loss : 4.01053274790446\n",
            "-------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ly3BoczGBm8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "3f6d3f6f-ba47-4c7a-9040-c5cfdce35f72"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        " \n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "plt.plot(train_loss, label='Train loss')\n",
        "plt.plot(valid_loss, label='Validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A8oxFr1jm17P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "e05de734-84f1-41c4-df9c-14b935cba468"
      },
      "source": [
        "get_per(data_loader_val_letters,cpc_model,character_classifier)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r                                                                               \r\rN/A% (0 of 19) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Starting the PER computation through beam search\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (19 of 19) |########################| Elapsed Time: 0:02:18 Time:  0:02:18\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Average CER 0.9822219069800113\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9822219069800113"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbmfpeLOUvOm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "e4630e5d-1afa-4533-e30b-4cebed70187b"
      },
      "source": [
        "get_per(data_loader_test_letters,cpc_model,character_classifier)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r                                                                               \r\rN/A% (0 of 56) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Starting the PER computation through beam search\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (56 of 56) |########################| Elapsed Time: 0:10:48 Time:  0:10:48\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Average CER 0.9765237950956754\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9765237950956754"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbx20uwOiOBY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}